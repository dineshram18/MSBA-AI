{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "cognitive_key = '0ed93a954f1c4e2099e561822e58cdc5'\n",
        "cognitive_endpoint = 'https://text01.cognitiveservices.azure.com/'\n",
        "\n",
        "print('Cognitive services ready at {}'.format(cognitive_key))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Cognitive services ready at 0ed93a954f1c4e2099e561822e58cdc5\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1719124841198
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install azure-ai-textanalytics"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: azure-ai-textanalytics in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (5.3.0)\nRequirement already satisfied: azure-core<2.0.0,>=1.24.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-textanalytics) (1.30.2)\nRequirement already satisfied: azure-common~=1.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-textanalytics) (1.1.28)\nRequirement already satisfied: isodate<1.0.0,>=0.6.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-textanalytics) (0.6.1)\nRequirement already satisfied: typing-extensions>=4.0.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-ai-textanalytics) (4.12.2)\nRequirement already satisfied: requests>=2.21.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (2.32.3)\nRequirement already satisfied: six>=1.11.0 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (2.2.1)\nRequirement already satisfied: certifi>=2017.4.17 in /anaconda/envs/azureml_py310_sdkv2/lib/python3.10/site-packages (from requests>=2.21.0->azure-core<2.0.0,>=1.24.0->azure-ai-textanalytics) (2024.6.2)\nNote: you may need to restart the kernel to use updated packages.\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719124845083
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azure.core.credentials import AzureKeyCredential\n",
        "from azure.ai.textanalytics import TextAnalyticsClient\n",
        "\n",
        "credential = AzureKeyCredential(cognitive_key)\n",
        "text_analytics_client = TextAnalyticsClient(endpoint=cognitive_endpoint, credential=credential)"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719124845276
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Language Detection\n",
        "documents = [\n",
        "    \"This is written in English.\",\n",
        "    \"Ceci est écrit en Français.\",\n",
        "    \"Dies ist in deutscher Sprache geschrieben.\"\n",
        "]\n",
        "language_analysis = text_analytics_client.detect_language(documents)\n",
        "result = [doc for doc in language_analysis if not doc.is_error]\n",
        "for doc in result:\n",
        "    print(\"Language detected: {}\".format(doc.primary_language.name))\n",
        "    print(\"ISO6391 name: {}\".format(doc.primary_language.iso6391_name))\n",
        "    print(\"Confidence score: {}\\n\".format(doc.primary_language.confidence_score))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Language detected: English\nISO6391 name: en\nConfidence score: 1.0\n\nLanguage detected: French\nISO6391 name: fr\nConfidence score: 1.0\n\nLanguage detected: German\nISO6391 name: de\nConfidence score: 1.0\n\n"
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719124845374
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Language Detection\n",
        "documents = [\n",
        "    \"I'm in love with Azure Text Analytics\",\n",
        "    \"AI is going to eat our jobs. We will all end up homeless.\",\n",
        "    \"Machine Learning skills are always valuable.\"\n",
        "]\n",
        "language_analysis = text_analytics_client.detect_language(documents)\n",
        "result = [doc for doc in language_analysis if not doc.is_error]\n",
        "for doc in result:\n",
        "    print(\"Language detected: {}\".format(doc.primary_language.name))\n",
        "    print(\"ISO6391 name: {}\".format(doc.primary_language.iso6391_name))\n",
        "    print(\"Confidence score: {}\\n\".format(doc.primary_language.confidence_score))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Language detected: English\nISO6391 name: en\nConfidence score: 1.0\n\nLanguage detected: English\nISO6391 name: en\nConfidence score: 1.0\n\nLanguage detected: English\nISO6391 name: en\nConfidence score: 1.0\n\n"
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719124845468
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Language Detection\n",
        "documents = [\n",
        "    \"Northwood University is the perfect place to learn by practice and exercise.\",\n",
        "    \"I might eat a burger tonight.\",\n",
        "    \"The answer to everything in life is 42.\"\n",
        "]\n",
        "language_analysis = text_analytics_client.detect_language(documents)\n",
        "result = [doc for doc in language_analysis if not doc.is_error]\n",
        "for doc in result:\n",
        "    print(\"Language detected: {}\".format(doc.primary_language.name))\n",
        "    print(\"ISO6391 name: {}\".format(doc.primary_language.iso6391_name))\n",
        "    print(\"Confidence score: {}\\n\".format(doc.primary_language.confidence_score))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Language detected: English\nISO6391 name: en\nConfidence score: 1.0\n\nLanguage detected: English\nISO6391 name: en\nConfidence score: 1.0\n\nLanguage detected: English\nISO6391 name: en\nConfidence score: 1.0\n\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719124845564
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Language Detection\n",
        "documents = [\n",
        "    \"Mighty woke up very early.\",\n",
        "    \"When she was in Paris, Grace was a happy girl.\",\n",
        "    \"He found a job thanks to Northwood University.\"\n",
        "]\n",
        "language_analysis = text_analytics_client.detect_language(documents)\n",
        "result = [doc for doc in language_analysis if not doc.is_error]\n",
        "for doc in result:\n",
        "    print(\"Language detected: {}\".format(doc.primary_language.name))\n",
        "    print(\"ISO6391 name: {}\".format(doc.primary_language.iso6391_name))\n",
        "    print(\"Confidence score: {}\\n\".format(doc.primary_language.confidence_score))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Language detected: English\nISO6391 name: en\nConfidence score: 1.0\n\nLanguage detected: English\nISO6391 name: en\nConfidence score: 1.0\n\nLanguage detected: English\nISO6391 name: en\nConfidence score: 1.0\n\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719124845677
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Sentiment Analysis\n",
        "documents = [\n",
        "    \"I'm in love with Azure Text Analytics\",\n",
        "    \"AI is going to eat our jobs. We will all end up homeless.\",\n",
        "    \"Machine Learning skills are always valuable.\"\n",
        "    ]\n",
        "\n",
        "response = text_analytics_client.analyze_sentiment(documents, language=\"en\")\n",
        "result = [doc for doc in response if not doc.is_error]\n",
        "\n",
        "for doc in result:\n",
        "    print(\"Overall sentiment: {}\".format(doc.sentiment))\n",
        "    print(\"Scores: positive={}; neutral={}; negative={} \\n\".format(\n",
        "        doc.confidence_scores.positive,\n",
        "        doc.confidence_scores.neutral,\n",
        "        doc.confidence_scores.negative,\n",
        "    ))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overall sentiment: positive\nScores: positive=1.0; neutral=0.0; negative=0.0 \n\nOverall sentiment: negative\nScores: positive=0.02; neutral=0.2; negative=0.79 \n\nOverall sentiment: positive\nScores: positive=0.81; neutral=0.19; negative=0.0 \n\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719124845768
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Key Phrase Extraction\n",
        "documents = [\n",
        "    \"Northwood University is the perfect place to learn by practice and exercise.\",\n",
        "    \"I might eat a burger tonight.\",\n",
        "    \"The answer to everything in life is 42.\"\n",
        "]\n",
        "\n",
        "response = text_analytics_client.extract_key_phrases(documents, language=\"en\")\n",
        "result = [doc for doc in response if not doc.is_error]\n",
        "\n",
        "for doc in result:\n",
        "    print(doc.key_phrases)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "['Northwood University', 'perfect place', 'practice', 'exercise']\n['burger']\n['answer', 'everything', 'life']\n"
        }
      ],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719124845854
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Entity Recognition\n",
        "documents = [\n",
        "    \"Mighty woke up very early.\",\n",
        "    \"When she was in Paris, Grace was a happy girl.\",\n",
        "    \"He found a job thanks to Northwood University.\"\n",
        "]\n",
        "\n",
        "response = text_analytics_client.recognize_entities(documents, language=\"en\")\n",
        "result = [doc for doc in response if not doc.is_error]\n",
        "\n",
        "for doc in result:\n",
        "    for entity in doc.entities:\n",
        "        print(\"Entity: \\t\", entity.text, \"\\tCategory: \\t\", entity.category,\n",
        "              \"\\tConfidence Score: \\t\", entity.confidence_score)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Entity: \t Mighty \tCategory: \t Person \tConfidence Score: \t 0.99\nEntity: \t Paris \tCategory: \t Location \tConfidence Score: \t 1.0\nEntity: \t Grace \tCategory: \t Person \tConfidence Score: \t 1.0\nEntity: \t Northwood University \tCategory: \t Organization \tConfidence Score: \t 1.0\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719124845941
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Language Detection\n",
        "documents = [\n",
        "    \"This is written in English.\",\n",
        "    \"ಈ ಯೋಜನೆಯು ನೈಸರ್ಗಿಕ ಭಾಷಾ ಸಂಸ್ಕರಣೆಯನ್ನು ಆಧರಿಸಿದೆ\",\n",
        "    \"Este proyecto se basa en el procesamiento del lenguaje natural.\"\n",
        "]\n",
        "language_analysis = text_analytics_client.detect_language(documents)\n",
        "result = [doc for doc in language_analysis if not doc.is_error]\n",
        "for doc in result:\n",
        "    print(\"Language detected: {}\".format(doc.primary_language.name))\n",
        "    print(\"ISO6391 name: {}\".format(doc.primary_language.iso6391_name))\n",
        "    print(\"Confidence score: {}\\n\".format(doc.primary_language.confidence_score))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Language detected: English\nISO6391 name: en\nConfidence score: 1.0\n\nLanguage detected: Kannada\nISO6391 name: kn\nConfidence score: 1.0\n\nLanguage detected: Spanish\nISO6391 name: es\nConfidence score: 1.0\n\n"
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719124846021
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Sentiment Analysis\n",
        "documents = [\n",
        "    \"I'm in love with Azure Text Analytics\",\n",
        "    \"AI is a very helpful tool,when used efficiently.\",\n",
        "    \"The future of mankind will evovle, when AI is established in all fields.\"\n",
        "    ]\n",
        "\n",
        "response = text_analytics_client.analyze_sentiment(documents, language=\"en\")\n",
        "result = [doc for doc in response if not doc.is_error]\n",
        "\n",
        "for doc in result:\n",
        "    print(\"Overall sentiment: {}\".format(doc.sentiment))\n",
        "    print(\"Scores: positive={}; neutral={}; negative={} \\n\".format(\n",
        "        doc.confidence_scores.positive,\n",
        "        doc.confidence_scores.neutral,\n",
        "        doc.confidence_scores.negative,\n",
        "    ))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overall sentiment: positive\nScores: positive=1.0; neutral=0.0; negative=0.0 \n\nOverall sentiment: positive\nScores: positive=0.99; neutral=0.01; negative=0.0 \n\nOverall sentiment: neutral\nScores: positive=0.02; neutral=0.97; negative=0.0 \n\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719124966901
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Key Phrase Extraction\n",
        "documents = [\n",
        "    \"I'm glad i chose Northwood University for my Graduate program.\",\n",
        "    \"I am hungry and don't know what to cook for dinner.\",\n",
        "    \"Life has to be lived one day at a time.\"\n",
        "]\n",
        "\n",
        "response = text_analytics_client.extract_key_phrases(documents, language=\"en\")\n",
        "result = [doc for doc in response if not doc.is_error]\n",
        "\n",
        "for doc in result:\n",
        "    print(doc.key_phrases)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "['Northwood University', 'Graduate program']\n['dinner']\n['Life', 'time']\n"
        }
      ],
      "execution_count": 13,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719125097148
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Entity Recognition\n",
        "documents = [\n",
        "    \"Zoey littered three puppies.\",\n",
        "    \"When he was swimming, Bruce was a satisfied man.\",\n",
        "    \"He found the love of his life when on a vacation in London.\"\n",
        "]\n",
        "\n",
        "response = text_analytics_client.recognize_entities(documents, language=\"en\")\n",
        "result = [doc for doc in response if not doc.is_error]\n",
        "\n",
        "for doc in result:\n",
        "    for entity in doc.entities:\n",
        "        print(\"Entity: \\t\", entity.text, \"\\tCategory: \\t\", entity.category,\n",
        "              \"\\tConfidence Score: \\t\", entity.confidence_score)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Entity: \t Zoey \tCategory: \t Person \tConfidence Score: \t 1.0\nEntity: \t three \tCategory: \t Quantity \tConfidence Score: \t 0.8\nEntity: \t Bruce \tCategory: \t Person \tConfidence Score: \t 1.0\nEntity: \t vacation \tCategory: \t Event \tConfidence Score: \t 0.57\nEntity: \t London \tCategory: \t Location \tConfidence Score: \t 1.0\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1719125265872
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      },
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}